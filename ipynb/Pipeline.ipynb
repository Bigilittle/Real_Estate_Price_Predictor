{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from dirty_cat import MinHashEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import plotly.express as px\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.distance import geodesic\n",
    "import json\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%script false\n",
    "main_data = pd.read_csv('data/data.csv', sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(377184, 18)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = main_data.copy()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PrivatePoolTransformer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X: pd.DataFrame, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X: pd.DataFrame):\n",
    "        X['PrivatePool'] = X['private pool'].combine_first(X['PrivatePool'])\n",
    "        X.drop('private pool', axis=1, inplace=True)\n",
    "        X['PrivatePool'] = X['PrivatePool'].map({'yes': True, 'Yes': True}).fillna(False).astype(bool)\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FireplaceTransformer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X: pd.DataFrame, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X: pd.DataFrame):\n",
    "        X['count_fireplace'] = X['fireplace'].apply(lambda x: self._handle_missing(x) if isinstance(x, str) else np.nan)\n",
    "        X['count_fireplace'] = X['count_fireplace'].fillna(X['fireplace'].apply(lambda x: self._extract_number(x) if isinstance(x, str) else np.nan))\n",
    "        X['count_fireplace'] = X['count_fireplace'].fillna(X['fireplace'].apply(lambda x: self._count_rooms(x) if isinstance(x, str) else np.nan))\n",
    "        X['count_fireplace'] = X['count_fireplace'].fillna(0)\n",
    "\n",
    "        X['fireplace_type'] = X['fireplace'].apply(self._identify_fireplace_type)\n",
    "        X.drop('fireplace', axis=1, inplace=True)\n",
    "        return X\n",
    "\n",
    "\n",
    "    def _extract_number(self, value: str):\n",
    "        value = value.lower()\n",
    "        text_to_number = {\n",
    "            'one': 1, 'two': 2, 'three': 3, 'four': 4,\n",
    "            'five': 5, 'six': 6, 'seven': 7, 'eight': 8,\n",
    "            'nine': 9, 'ten': 10, 'eleven': 11, 'twelve': 12\n",
    "        }\n",
    "        for text, num in text_to_number.items():\n",
    "            if text in value:\n",
    "                return num\n",
    "        match = re.search(r'(\\d+)(?=\\+)?', value)\n",
    "        if match:\n",
    "            return int(match.group(1))\n",
    "        elif 'yes' in value.lower():\n",
    "            return 1\n",
    "        else:\n",
    "            return np.nan\n",
    "    \n",
    "    def _count_rooms(self, value: str):\n",
    "        room_types = ['Family', 'Bedroom', 'Living', 'Den', 'Kitchen', 'Dining', 'FAMILYRM',\n",
    "                      'Library', 'Study', 'Playroom', 'Recreation', 'Sitting', 'Guest', 'Office']\n",
    "        count = sum(value.count(room) for room in room_types)\n",
    "        return count if count > 0 else 1\n",
    "    \n",
    "    def _handle_missing(self, value: str):\n",
    "        if isinstance(value, str) and value in ['N/K', 'No', 'Not Applicable', 'None', 'Non-Functional', 'Inoperative', 'Extra Closets']:\n",
    "            return 0\n",
    "\n",
    "    def _identify_fireplace_type(self, value: str):\n",
    "        if isinstance(value, str):\n",
    "            value = value.lower()\n",
    "            if 'gas' in value:\n",
    "                return 1\n",
    "            if 'wood' in value or 'burning' in value:\n",
    "                return 2\n",
    "            if 'electric' in value:\n",
    "                return 3\n",
    "        return 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StatusToNumberTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.status_groups = {\n",
    "            'For Sale/Active': [\n",
    "                'for sale', 'active', 'new construction', 'new', 'active under contract', \n",
    "                'active with offer', 'active/contingent', 'active - auction', 'active with contract', \n",
    "                'auction active', 'auction', 'back on market', 'listing extended', 'active option', \n",
    "                'price change', 'a active', 'temporary active'\n",
    "            ],\n",
    "            'Pending/Under Contract': [\n",
    "                'pending', 'under contract', 'contingent', 'pending continue to show', 'p',\n",
    "                'option pending', 'pending taking backups', 'under contract show', 'under contract showing', \n",
    "                'under contract backups', 'pending backup wanted', 'pending take backups', \n",
    "                'pending continue show', 'pending inspection', 'due diligence period', 'p pending sale',\n",
    "                'active with contingencies', 'pending ab', 'contingent finance and inspection',\n",
    "                'contingent show', 'contingent take backup', 'pf', 'under contract showing', \n",
    "                'c', 'ct', 'pending - continue to show', 'pending (do not show)',\n",
    "                'pending - backup offer requested', 'pending w/backup wanted', 'option contract',\n",
    "                'pending - taking backups', 'offer pending signature', 'pending fe',\n",
    "                'pending w/insp finance', 'uc continue to show', 'contingency contract',\n",
    "                'under contract - show', 'pending offer approval', 'contingent escape',\n",
    "                'pending with contingencies', 'contingent - financing', 'contract contingent on buyer sale',\n",
    "                'pending, continue to show', 'pending bring backup', 'pending w/ escape clause',\n",
    "                'pending - continue to show', 'pending sh', 'pending w/ cont.', \n",
    "                'pending continue to show   financing', 'pending inspection', \n",
    "                'under contract taking back up offers', 'backup contract', 'backup',\n",
    "                'contract p', 'contingency 48 hr (+/ )', 'conting accpt backups',\n",
    "                'contingent release', 'contingent lien holder release', 'contingent - sale of home',\n",
    "                'pending sale', 'pending - continue to show', 'contingent foreclosure','under contract   showing'\n",
    "            ],\n",
    "            'Foreclosure/Auction': [\n",
    "                'foreclosure', 'pre-foreclosure', 'foreclosed', 'auction', 'pre-foreclosure / auction', \n",
    "                'auction - active', ' / auction', 'pending auction', 'auction - active', 'foreclosure auction'\n",
    "            ],\n",
    "        }\n",
    "\n",
    "    def fit(self, X: pd.DataFrame, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X: pd.DataFrame):\n",
    "        X['status'] = X['status'].apply(self._status_to_number)\n",
    "        return X\n",
    "\n",
    "    def _status_to_number(self, value: str):\n",
    "        if pd.isna(value):\n",
    "            return 0 # Создадим отдельный статус для пропущенных значений\n",
    "        \n",
    "        value = value.lower()\n",
    "        for index, (key, statuses) in enumerate(self.status_groups.items()):\n",
    "            statuses_lower = [status.lower() for status in statuses]\n",
    "            \n",
    "            if value in statuses_lower:\n",
    "                return index + 1\n",
    "        \n",
    "        return 4  # Возвращаем 4, если статус не найден\n",
    "    \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StoriesTransform(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.word_to_num={\n",
    "        \"one half\":0.5, \"one\": 1, \"two\": 2, \"three\": 3, \"four\": 4, \n",
    "        \"five\": 5, \"six\": 6, \"seven\": 7, \"eight\": 8, \"nine\": 9, \"ten\": 10,\n",
    "        \"duplex\":2, \"ground\":1, \"triplex\":3, 'tri':3\n",
    "    }\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X: pd.DataFrame):\n",
    "        X['stories'] = X['stories'].apply(self._process_stories)\n",
    "        return X\n",
    "\n",
    "    def _process_stories(self, story: str):\n",
    "        if pd.isna(story):\n",
    "            return np.nan  # Создадим отдельный статус для пропущенных значений\n",
    "\n",
    "\n",
    "        # Step 2: Process known words\n",
    "        stories = 0\n",
    "\n",
    "        # Convert the story to lower case for consistency\n",
    "        story = story.lower()\n",
    "\n",
    "        # Replace known words with numbers\n",
    "        for word, num in self.word_to_num.items():\n",
    "            story = story.replace(word, str(num))\n",
    "\n",
    "        # Extract numbers after replacing words\n",
    "        numbers = re.findall(r'\\d+\\.?\\d*', story)\n",
    "        if numbers:\n",
    "            stories += sum([float(num) for num in numbers]) / len(numbers)\n",
    "\n",
    "        # Add 0.5 if \"Basement\" or related term is mentioned\n",
    "        story = story.replace('-', ' ')\n",
    "        if \"basement\" in story or \"tri level\" in story:\n",
    "            stories += 0.5\n",
    "\n",
    "        # Mark all unprocessed stories as \"Unknown\"\n",
    "        return stories if stories > 0 else np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PropertyTypeTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.replacements = {\n",
    "            r'single[\\s_-]*family[\\s_-]*home|single[\\s_-]*family[\\s_-]*': 'single_family_home',\n",
    "            r'condo|condo/townhome.*|coop.*': 'condo',\n",
    "            r'townhouse|row home|townhome': 'townhouse',\n",
    "            r'multi[\\s_-]*family': 'multi_family_home',\n",
    "            r'lot/land|land|farms/ranches': 'land',\n",
    "            r'mobile': 'mobile_home',\n",
    "            r'apartment': 'apartment',\n",
    "            r'ranch': 'ranch',\n",
    "            r'contemporary|modern|contemporary/modern': 'contemporary_modern',\n",
    "            r'colonial': 'colonial',\n",
    "            r'traditional': 'traditional',\n",
    "            r'1 story|one story': 'one_story',\n",
    "            r'2 stories|two story': 'two_story',\n",
    "            r'other': 'other'\n",
    "        }\n",
    "\n",
    "        self.cat_type_encoder = joblib.load('pkl/property_type_encoder.pkl')\n",
    "    \n",
    "    def fit(self, X: pd.DataFrame, y=None):\n",
    "        # В методе fit ничего не делаем, так как энкодер уже обучен\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X: pd.DataFrame):\n",
    "        X['propertyType'] = X['propertyType'].str.lower().str.strip()\n",
    "        X['propertyType'] = X['propertyType'].apply(self.clean_property_type)\n",
    "        \n",
    "        # Применение замен\n",
    "        for pattern, replacement in self.replacements.items():\n",
    "            X['propertyType'] = X['propertyType'].replace(to_replace=pattern, value=replacement, regex=True)\n",
    "        \n",
    "        X['propertyType'] = self.cat_type_encoder.transform(X[['propertyType']])\n",
    "        return X\n",
    "    \n",
    "    def clean_property_type(self, pt):\n",
    "        if pd.isna(pt):\n",
    "            return 'missing'  # Создадим отдельный статус для пропущенных значений\n",
    "\n",
    "        pt = re.sub(r'\\b(\\w+)(_\\1\\b)+', r'\\1', pt)\n",
    "        pt = re.sub(r'\\b(\\w+)(/\\1\\b)+', r'\\1', pt)\n",
    "        \n",
    "        pt = re.sub(r'\\s+/|/\\s+', '/', pt)\n",
    "        pt = re.sub(r'\\s+', '_', pt)\n",
    "        pt = re.sub(r'(_{2,})', '_', pt)\n",
    "        pt = re.sub(r'(_home)+', '_home', pt)\n",
    "        pt = re.sub(r'(_story)+', '_story', pt)\n",
    "        pt = re.sub(r'\\bhome_home\\b', 'home', pt)\n",
    "        \n",
    "        return pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class HomeFeaturesExtractor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.columns = ['Cooling', 'Heating', 'Parking', 'Price/sqft', 'Remodeled year', 'Year built', 'lotsize']\n",
    "\n",
    "    def fit(self, X: pd.DataFrame, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X: pd.DataFrame) -> pd.DataFrame:\n",
    "        if 'homeFacts' not in X.columns:\n",
    "            raise ValueError(\"DataFrame must contain 'homeFacts' column\")\n",
    "\n",
    "        # Применение функции для извлечения признаков\n",
    "        new_columns = X['homeFacts'].apply(self.extract_home_features)\n",
    "        new_df = pd.DataFrame(new_columns.tolist())\n",
    "        X.drop('homeFacts', inplace=True, axis=1)\n",
    "        \n",
    "        return X.join(new_df)\n",
    "\n",
    "    def extract_home_features(self, home_facts_str: str):\n",
    "        if pd.isna(home_facts_str):\n",
    "            return {col: np.nan for col in self.columns}\n",
    "        \n",
    "        try:\n",
    "            home_facts_str = home_facts_str.replace(\"'\", '\"')\n",
    "            home_facts_str = home_facts_str.replace('\"closet\"-Electric', 'closet-Electric')\n",
    "            home_facts_str = re.sub(r'(?<!\")\\bNone\\b(?!\")', '\"None\"', home_facts_str)\n",
    "            home_facts_str = re.sub(r'(?<=[a-z-A-Z])\"(?=[a-zA-Z])', '/', home_facts_str)\n",
    "\n",
    "            home_facts_dict = json.loads(home_facts_str)\n",
    "            facts = home_facts_dict.get('atAGlanceFacts', [])\n",
    "            features = {fact['factLabel']: fact['factValue'] for fact in facts}\n",
    "            return {col: features.get(col, np.nan) for col in self.columns}\n",
    "        \n",
    "        except json.JSONDecodeError as e:\n",
    "            print(\"Ошибка декодирования JSON:\")\n",
    "            print(f\"Сообщение об ошибке: {e}\")\n",
    "            print(f\"Проблемная строка JSON: {home_facts_str}\")\n",
    "            return {col: np.nan for col in self.columns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SchoolFeaturesExtractor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.columns = ['Average Rating', 'Highest Rating', 'Lowest Rating']\n",
    "\n",
    "    def fit(self, X: pd.DataFrame, y=None):\n",
    "        # Никаких операций обучения не требуется\n",
    "        return self\n",
    "\n",
    "    def transform(self, X: pd.DataFrame) -> pd.DataFrame:\n",
    "        # Применение функции для извлечения признаков\n",
    "        new_columns = X['schools'].apply(self.extract_school_features)\n",
    "        new_df = pd.DataFrame(new_columns.tolist(), columns=self.columns)\n",
    "        X.drop('schools', inplace=True, axis=1)\n",
    "\n",
    "\n",
    "        return X.join(new_df)\n",
    "\n",
    "    def extract_school_features(self, school_facts_str: str):\n",
    "        if pd.isna(school_facts_str):\n",
    "            return {\n",
    "                'Average Rating': np.nan\n",
    "          \n",
    "            }\n",
    "\n",
    "        try:\n",
    "        \n",
    "            school_facts_str = school_facts_str.replace(\"'\", '\"')\n",
    "            school_facts_str = re.sub(r'(?<!\")\\bNone\\b(?!\")', '\"None\"', school_facts_str)\n",
    "            school_facts_str = re.sub(r'NR', 'None', school_facts_str)\n",
    "            school_facts_str = re.sub(r'NA', 'None', school_facts_str)\n",
    "            school_facts_str = re.sub(r'(?<=[a-z-A-Z])\"(?=[a-zA-Z])', '/', school_facts_str)\n",
    "            school_facts_str = re.sub(r', \"name\": \\[[^\\]]*\\]', '', school_facts_str)\n",
    "\n",
    "            features = json.loads(school_facts_str)[0]\n",
    "            #data = features.get('data', []) \n",
    "\n",
    "            try: #отвечает за рейтинг школ\n",
    "                ratings = []\n",
    "                for rating in features['rating']:\n",
    "                    if 'None' not in rating:\n",
    "                        rating_value = rating.split('/')[0]  # Берем значение до '/'\n",
    "                        ratings.append(int(rating_value))\n",
    "            except:\n",
    "                ratings=[]\n",
    "\n",
    "    \n",
    "\n",
    "            return {\n",
    "                'Average Rating': np.mean(ratings) if ratings else np.nan\n",
    "            }\n",
    "\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"JSONDecodeError: {e}\")\n",
    "            print(f'Problematic string: {school_facts_str}')\n",
    "            return {\n",
    "                'Average Rating': np.nan\n",
    "            }\n",
    "        except Exception as err: \n",
    "            print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "class fill_sqft():\n",
    "    def __init__(self, cols):\n",
    "        self.cols_to_check = cols\n",
    "\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return self.fill_sqft_from_columns(X, self.cols_to_check)\n",
    "\n",
    "    def extract_sqft(self, text):\n",
    "        if pd.isna(text):\n",
    "            return np.nan\n",
    "        text = str(text).replace(',', '')  # Удаляем запятые\n",
    "        match = re.search(r'(\\d+)\\s?sqft', text)  # Ищем число, за которым идет 'sqft'\n",
    "        if match:\n",
    "            return float(match.group(1))  # Возвращаем найденное число как float\n",
    "        return np.nan\n",
    "\n",
    "    # Заполнение пропущенных значений в столбце sqft\n",
    "    def fill_sqft_from_columns(self, X, cols_to_check):\n",
    "        for col in cols_to_check:\n",
    "            # Ищем информацию о площади в каждом указанном столбце\n",
    "            X['sqft'] = X.apply(\n",
    "                lambda row: self.extract_sqft(row[col]) if pd.isna(row['sqft']) else row['sqft'], \n",
    "                axis=1\n",
    "            )\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumericExtractor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self, X: pd.DataFrame, y=None):\n",
    "        # Никаких операций обучения не требуется\n",
    "        return self\n",
    "\n",
    "    def transform(self, X: pd.DataFrame) -> pd.DataFrame:\n",
    "        # Проверка наличия всех колонок в DataFrame\n",
    "        for col in self.columns:\n",
    "            if col not in X.columns:\n",
    "                raise ValueError(f\"DataFrame must contain column '{col}'\")\n",
    "            else:\n",
    "                X[col] = X[col].apply(self.give_number)\n",
    "        \n",
    "       \n",
    "        return X\n",
    "\n",
    "    def give_number(self, pt):\n",
    "        if pd.isna(pt):\n",
    "            return np.nan\n",
    "        pt = str(pt).replace(',', '')\n",
    "        match = re.search(r'\\d+\\.?\\d*', str(pt)) \n",
    "        if match:\n",
    "            return float(match.group())  \n",
    "        else:\n",
    "            return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParkingPriceTransformer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X: pd.DataFrame, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X: pd.DataFrame) -> pd.DataFrame:\n",
    "        # Преобразуем столбец 'Parking'\n",
    "        X['Parking'] = X['Parking'].apply(self.extract_number_second)\n",
    "        X['Parking'] = X['Parking'].fillna(0)\n",
    "\n",
    "        # Преобразуем столбец 'Price/sqft'\n",
    "        X['Price/sqft'] = X['Price/sqft'].apply(self.extract_number_second).astype(float)\n",
    "\n",
    "        return X\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_number_second(value):\n",
    "        if pd.isna(value):\n",
    "            return np.nan  # Для пропущенных значений\n",
    "\n",
    "        # Удаление пробелов и приведение к нижнему регистру\n",
    "        value = value.strip().lower()\n",
    "\n",
    "        # Проверка на отсутствие данных\n",
    "        if 'no data' in value or 'no parking' in value:\n",
    "            return 0\n",
    "\n",
    "        # Поиск числа в строке\n",
    "        match = re.search(r'\\b(\\d+)\\s*spaces?\\b', value)\n",
    "        if match:\n",
    "            return int(match.group(1))\n",
    "\n",
    "        # Поиск явного числа в строке\n",
    "        match = re.search(r'\\b(\\d+)\\b', value)\n",
    "        if match:\n",
    "            return int(match.group(1))\n",
    "\n",
    "        # Если не удалось найти данные\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImputerOutlierRemover(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, quantile_low=0.10, quantile_high=0.90, iqr_multiplier=1.5):\n",
    "        self.quantile_low = quantile_low\n",
    "        self.quantile_high = quantile_high\n",
    "        self.iqr_multiplier = iqr_multiplier\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "  \n",
    "        # Сохраняем медиану и вычисляем границы для выбросов\n",
    "        self.median_ = X['stories'].median()\n",
    "        #new_X = X['stories'].fillna(self.median_)\n",
    "        time_data=X['stories'].fillna(self.median_ )\n",
    "\n",
    "        Q1 = time_data.quantile(self.quantile_low)\n",
    "        Q3 = time_data.quantile(self.quantile_high)\n",
    "        self.IQR_ = Q3 - Q1\n",
    "        self.lower_bound_ = Q1 - self.iqr_multiplier * self.IQR_\n",
    "        self.upper_bound_ = Q3 + self.iqr_multiplier * self.IQR_\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        if 'stories' not in X.columns:\n",
    "            raise ValueError(\"Column 'stories' not found in the input DataFrame\")\n",
    "        # Заполняем пропуски медианным значением\n",
    "        X['stories'] = X['stories'].fillna(self.median_)\n",
    "        # Удаляем выбросы\n",
    "        X = X[(X['stories'] >= self.lower_bound_) & (X['stories'] <= self.upper_bound_)]\n",
    "        #X.drop('Remodeled year', axis=1, inplace=True)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParkingMinHashEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_components=5, fill_value='No Data'):\n",
    "        self.n_components = n_components\n",
    "        self.fill_value = fill_value\n",
    "        self.minhash_encoder = MinHashEncoder(n_components=self.n_components)\n",
    "\n",
    "    def fit(self, X: pd.DataFrame, y=None):\n",
    "        # Заполнение пропусков и обучение MinHashEncoder\n",
    "        X_filled = X['Parking'].fillna(self.fill_value)\n",
    "        self.minhash_encoder.fit(X_filled.values.reshape(-1, 1))\n",
    "        return self\n",
    "\n",
    "    def transform(self, X: pd.DataFrame):\n",
    "        # Заполнение пропусков и применение MinHashEncoder\n",
    "        X_filled = X['Parking'].fillna(self.fill_value)\n",
    "        encoded_parking = self.minhash_encoder.transform(X_filled.values.reshape(-1, 1))\n",
    "\n",
    "        # Преобразование результата в DataFrame\n",
    "        encoded_parking_df = pd.DataFrame(\n",
    "            encoded_parking, \n",
    "            columns=[f'Parking_{i}' for i in range(encoded_parking.shape[1])]\n",
    "        )\n",
    "\n",
    "        # Сброс индекса у обоих DataFrame\n",
    "        X.reset_index(drop=True, inplace=True)\n",
    "        encoded_parking_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        # Удаление старого столбца Parking и объединение с новым\n",
    "        X_encoded = pd.concat([X, encoded_parking_df], axis=1)\n",
    "        X_encoded.drop('Parking', axis=1, inplace=True)\n",
    "        return X_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from dirty_cat import MinHashEncoder\n",
    "\n",
    "class CoolingTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_components=3):\n",
    "        self.n_components = n_components\n",
    "        self.encoder = MinHashEncoder(n_components=self.n_components)\n",
    "\n",
    "    def fit(self, X: pd.DataFrame, y=None):\n",
    "        # Обучаем только MinHashEncoder на столбце 'Cooling'\n",
    "        X['Cooling_Categorized'] = X['Cooling'].apply(self.process_cooling)\n",
    "        self.encoder.fit(X[['Cooling_Categorized']])\n",
    "        return self\n",
    "\n",
    "    def transform(self, X: pd.DataFrame) -> pd.DataFrame:\n",
    "        # Преобразуем столбец 'Cooling'\n",
    "        X['Cooling_Categorized'] = X['Cooling'].apply(self.process_cooling)\n",
    "\n",
    "        # Заполняем пропущенные значения модой\n",
    "        X['Cooling_Categorized'] = X['Cooling_Categorized'].fillna(X['Cooling_Categorized'].mode()[0])\n",
    "\n",
    "        # Применяем MinHashEncoder\n",
    "        encoded = self.encoder.transform(X[['Cooling_Categorized']])\n",
    "\n",
    "        # Создаем DataFrame с закодированными признаками\n",
    "        encoded_df = pd.DataFrame(encoded, columns=[f'Cooling_{i}' for i in range(encoded.shape[1])])\n",
    "\n",
    "        # Объединяем закодированные признаки с исходным DataFrame\n",
    "        X.reset_index(drop=True, inplace=True)\n",
    "        X = pd.concat([X, encoded_df], axis=1)\n",
    "\n",
    "        # Удаляем исходные столбцы\n",
    "        X.drop(['Cooling', 'Cooling_Categorized'], axis=1, inplace=True)\n",
    "\n",
    "        return X\n",
    "\n",
    "    @staticmethod\n",
    "    def process_cooling(cooling_str):\n",
    "        \"\"\"\n",
    "        Функция для обработки столбца 'Cooling', которая классифицирует варианты систем охлаждения.\n",
    "        \"\"\"\n",
    "        if pd.isna(cooling_str):\n",
    "            return np.nan  # Для пропущенных значений\n",
    "\n",
    "        cooling_str = cooling_str.lower()  # Приведение к нижнему регистру\n",
    "        \n",
    "        # Категории и ключевые слова для каждой категории\n",
    "        if re.search(r'central|zoned', cooling_str):\n",
    "            return 'Central A/C'\n",
    "        elif re.search(r'window|wall', cooling_str):\n",
    "            return 'Window/Wall Unit'\n",
    "        elif re.search(r'heat pump', cooling_str):\n",
    "            return 'Heat Pump'\n",
    "        elif re.search(r'no a/c|no cooling', cooling_str):\n",
    "            return 'No A/C'\n",
    "        elif re.search(r'fan', cooling_str):\n",
    "            return 'Fan'\n",
    "        elif re.search(r'geothermal', cooling_str):\n",
    "            return 'Geothermal'\n",
    "        elif re.search(r'evaporative', cooling_str):\n",
    "            return 'Evaporative Cooler'\n",
    "        elif re.search(r'solar', cooling_str):\n",
    "            return 'Solar A/C'\n",
    "        else:\n",
    "            return 'Other'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class HeatingFeaturesTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_components=2):\n",
    "        self.n_components = n_components\n",
    "        self.encoder = MinHashEncoder(n_components=self.n_components)\n",
    "    \n",
    "    def fit(self, X: pd.DataFrame, y=None):\n",
    "        # Подготовка данных и обучение энкодера\n",
    "        if 'Heating' in X.columns:\n",
    "            X['Heating_Categorized'] = X['Heating'].apply(self.categorize_heating)\n",
    "            self.encoder.fit(X[['Heating_Categorized']])\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X: pd.DataFrame) -> pd.DataFrame:\n",
    "        if 'Heating' in X.columns:\n",
    "            # Преобразование значений\n",
    "            X['Heating_Categorized'] = X['Heating'].apply(self.categorize_heating)\n",
    "            \n",
    "            # Кодирование категорий\n",
    "            encoded = self.encoder.transform(X[['Heating_Categorized']])\n",
    "            encoded_df = pd.DataFrame(encoded, columns=[f'Heating_{i}' for i in range(encoded.shape[1])])\n",
    "            \n",
    "            # Объединение с исходным DataFrame\n",
    "            X = X.drop(['Heating', 'Heating_Categorized'], axis=1, errors='ignore')\n",
    "            X = pd.concat([X, encoded_df], axis=1)\n",
    "        return X\n",
    "\n",
    "    @staticmethod\n",
    "    def categorize_heating(heating):\n",
    "        if isinstance(heating, str):\n",
    "            heating = heating.lower()\n",
    "            # Газовое отопление\n",
    "            if any(x in heating for x in ['gas', 'natural gas', 'propane']):\n",
    "                return 'Gas'\n",
    "            # Электрическое отопление\n",
    "            elif any(x in heating for x in ['electric', 'electricity']):\n",
    "                return 'Electric'\n",
    "            # Тепловой насос\n",
    "            elif 'heat pump' in heating:\n",
    "                return 'Heat Pump'\n",
    "            # Печное отопление\n",
    "            elif any(x in heating for x in ['stove', 'wood', 'pellet']):\n",
    "                return 'Stove'\n",
    "            # Радиационное отопление\n",
    "            elif 'radiant' in heating or 'radiator' in heating:\n",
    "                return 'Radiant'\n",
    "            # Центральное отопление\n",
    "            elif 'central' in heating:\n",
    "                return 'Central'\n",
    "            # Другие типы\n",
    "            elif 'solar' in heating:\n",
    "                return 'Solar'\n",
    "            elif 'fireplace' in heating:\n",
    "                return 'Fireplace'\n",
    "            elif 'baseboard' in heating:\n",
    "                return 'Baseboard'\n",
    "            elif 'steam' in heating:\n",
    "                return 'Steam'\n",
    "            elif 'wall' in heating:\n",
    "                return 'Wall'\n",
    "            elif 'forced air' in heating:\n",
    "                return 'Forced Air'\n",
    "            else:\n",
    "                return 'Other'\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MinHashFeaturesTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns, n_components=2):\n",
    "        self.columns = columns\n",
    "        self.n_components = n_components\n",
    "\n",
    "    def fit(self, X: pd.DataFrame, y=None):\n",
    "        self.encoders_ = {}\n",
    "        for col in self.columns:\n",
    "            encoder = MinHashEncoder(n_components=self.n_components)\n",
    "            self.encoders_[col] = encoder.fit(X[[col]])\n",
    "        return self\n",
    "\n",
    "    def transform(self, X: pd.DataFrame) -> pd.DataFrame:\n",
    "        X = X.copy()  # Не изменяем оригинальный DataFrame\n",
    "        for col in self.columns:\n",
    "            encoder = self.encoders_.get(col)\n",
    "            if encoder:\n",
    "                encoded = encoder.transform(X[[col]])\n",
    "                encoded_df = pd.DataFrame(encoded, columns=[f'{col}_{i}' for i in range(encoded.shape[1])])\n",
    "                X = pd.concat([X, encoded_df], axis=1)\n",
    "        X = X.drop(self.columns, axis=1, errors='ignore')\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YearFeaturesTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X: pd.DataFrame, y=None):\n",
    "        # Никаких операций обучения не требуется\n",
    "        return self\n",
    "\n",
    "    def transform(self, X: pd.DataFrame) -> pd.DataFrame:\n",
    "        # Создаем копию данных, чтобы избежать изменений оригинала\n",
    "        X = X.copy()\n",
    "        \n",
    "        year_mode = X['Year built'].mode()[0]\n",
    "        X['Year built'] = X['Year built'].fillna(year_mode)\n",
    "        \n",
    "        \n",
    "        X = X.loc[(X['Year built'] >= 1850) & (X['Year built'] <= 2024)].copy()\n",
    "        X.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        # Добавляем новые признаки\n",
    "        X['is_remodeled'] = (X['Remodeled year'] > X['Year built']).fillna(False).astype(bool)\n",
    "        X['property_age'] = 2024 - X['Year built']\n",
    "        \n",
    "        # Удаляем старые столбцы\n",
    "        X.drop(['Year built', 'Remodeled year'], axis=1, inplace=True)\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.model_selection import KFold, cross_val_score, GridSearchCV\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class InplaceColTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, features, target):\n",
    "        self.features = features\n",
    "        self.target = target\n",
    "\n",
    "    def fit(self, X: pd.DataFrame, y=None):\n",
    "        # Фиттинг модели для заполнения пропущенных значений\n",
    "        self.model = self._fit_xgboost(X, self.features, self.target)\n",
    "        self._baseline_model(X, self.features, self.target)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X: pd.DataFrame) -> pd.DataFrame:\n",
    "        # Заполнение пропущенных значений\n",
    "        X = self._fillna_optimized(X, self.model, self.features, self.target)\n",
    "        return X\n",
    "\n",
    "    def _fit_xgboost(self, data: pd.DataFrame, columns: list, target: str):\n",
    "        df = data[columns + [target]]\n",
    "        X_missing = df[df[target].isnull()]\n",
    "        X_missing.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        Xy = df.dropna(subset=[target])\n",
    "        Xy.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        X = Xy[columns]\n",
    "        y = Xy[target]\n",
    "\n",
    "        param_grid = {\n",
    "            'n_estimators': [100, 150],\n",
    "            'learning_rate': [0.01, 0.1, 0.2],\n",
    "            'max_depth': [3, 5, 7],\n",
    "            'subsample': [0.8, 1.0],\n",
    "            'colsample_bytree': [0.8, 1.0]\n",
    "        }\n",
    "\n",
    "        model = xgb.XGBRegressor(random_state=42)\n",
    "\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=model,\n",
    "            param_grid=param_grid,\n",
    "            cv=5,\n",
    "            scoring='neg_mean_absolute_error',\n",
    "            n_jobs=-1,\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        grid_search.fit(X, y)\n",
    "        return grid_search.best_estimator_\n",
    "\n",
    "    def _baseline_model(self, data: pd.DataFrame, features: list, target: str):\n",
    "        data = data.dropna(subset=[target])\n",
    "        X = data[features]\n",
    "        y = data[target]\n",
    "\n",
    "        baseline = DummyRegressor(strategy='mean')\n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        mae_scores = cross_val_score(baseline, X, y, cv=kf, scoring='neg_mean_absolute_error')\n",
    "        mae_mean = -mae_scores.mean()\n",
    "\n",
    "        print(f\"Baseline MAE (Mean Absolute Error): {mae_mean}\", end='\\n\\n')\n",
    "\n",
    "    def _fillna_optimized(self, data: pd.DataFrame, model, features: list, target: str) -> pd.DataFrame:\n",
    "        mask = data[target].isnull()\n",
    "        features_to_predict = data.loc[mask, features]\n",
    "        predicted_values = model.predict(features_to_predict)\n",
    "        data.loc[mask, target] = predicted_values\n",
    "        return data\n",
    "\n",
    "class OutlierRemover(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X: pd.DataFrame, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X: pd.DataFrame) -> pd.DataFrame:\n",
    "        X = X.copy()\n",
    "        X = X[(X['baths'] < 10) | (X['baths'].isnull())]\n",
    "        X = X[(X['target'] <= 40e6) & (X['target'] > 1e3)]\n",
    "        X = X[(X['beds'] < 20) | (X['beds'].isnull())]\n",
    "        X = X[(X['Price/sqft'] < 4e3) | (X['Price/sqft'].isnull())]\n",
    "        return X\n",
    "    \n",
    "\n",
    "def round_to_nearest_half(value):\n",
    "    if pd.isna(value):\n",
    "            return np.nan\n",
    "    return round(value * 2) / 2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutlierRemover(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X: pd.DataFrame, y=None):\n",
    "        # Никаких операций обучения не требуется\n",
    "        return self\n",
    "\n",
    "    def transform(self, X: pd.DataFrame) -> pd.DataFrame:\n",
    "        # Создаем копию данных, чтобы избежать изменений оригинала\n",
    "        X = X.copy()\n",
    "        \n",
    "        # Удаление аномальных данных\n",
    "        X = X[(X['baths'] < 10) | (X['baths'].isnull())]\n",
    "        X = X[(X['target'] <= 40e6) & (X['target'] > 1e3)]\n",
    "        X = X[(X['beds'] < 20) | (X['beds'].isnull())]\n",
    "        X = X[(X['Price/sqft'] < 4e3) | (X['Price/sqft'].isnull())]\n",
    "\n",
    "        Q1 = X['sqft'].quantile(0.25)\n",
    "        Q3 = X['sqft'].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "\n",
    "        # Определение границ\n",
    "        lower_bound = 300\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "        # Фильтрация данных\n",
    "        X = X[(X['sqft'].isna()) |(X['sqft'] >= lower_bound) & (X['sqft'] <= upper_bound)]\n",
    "        X.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CustomFeatureTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        # Этот метод может быть оставлен пустым, так как мы не обучаем модель здесь\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        # Убедитесь, что X - это DataFrame\n",
    "        X = X.copy()\n",
    "        \n",
    "        # Обработка признака 'count_fireplace'\n",
    "        X['has_fireplace'] = X['count_fireplace'].apply(lambda x: 1 if x > 0 else 0)\n",
    "        X.drop(['count_fireplace'], axis=1, inplace=True)\n",
    "        \n",
    "        # Обработка признака 'Parking'\n",
    "        X['has_parking'] = X['Parking'].apply(lambda x: 1 if x > 0 else 0)\n",
    "        X.drop('Parking', axis=1, inplace=True)\n",
    "        \n",
    "        # Обработка признака 'lowest_price'\n",
    "        X['lowest_price'] = X['sqft'] * X['Price/sqft']\n",
    "        X = X[(X['lowest_price'] > 5)]\n",
    "        X.loc[X['lowest_price'] > 5e5, 'lowest_price'] = None\n",
    "        \n",
    "        # Обработка пропущенных значений в 'baths'\n",
    "        X.loc[X['baths'] == 0, 'baths'] = None\n",
    "        \n",
    "        # Создание новых признаков\n",
    "        X['sqft/baths'] = X['sqft'] / X['baths']\n",
    "        X['sum_baths_beds'] = X['beds'] + X['baths']\n",
    "        \n",
    "        # Удаление старых признаков\n",
    "        X.drop(['beds', 'baths'], axis=1, inplace=True)\n",
    "        \n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Other(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X: pd.DataFrame, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X: pd.DataFrame):\n",
    "        X.drop(['lotsize', 'stories'], axis=1, inplace=True)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "уходят в drop:  \n",
    "Parking  \n",
    "Cooling   \n",
    "Heating  \n",
    "lotsize  \n",
    "Price/sqft  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bigil\\AppData\\Local\\Temp\\ipykernel_13672\\2687220734.py:8: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X['PrivatePool'] = X['PrivatePool'].map({'yes': True, 'Yes': True}).fillna(False).astype(bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "Baseline MAE (Mean Absolute Error): 697.6074497944612\n",
      "\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "Baseline MAE (Mean Absolute Error): 0.765832995700708\n",
      "\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "Baseline MAE (Mean Absolute Error): 0.8318803837545431\n",
      "\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "Baseline MAE (Mean Absolute Error): 123.67270692656794\n",
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'private pool'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\project\\myenv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'private pool'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[158], line 35\u001b[0m\n\u001b[0;32m     32\u001b[0m data\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     34\u001b[0m data_pipeline\u001b[38;5;241m.\u001b[39mfit(data)\n\u001b[1;32m---> 35\u001b[0m pp \u001b[38;5;241m=\u001b[39m \u001b[43mdata_pipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\project\\myenv\\Lib\\site-packages\\sklearn\\pipeline.py:905\u001b[0m, in \u001b[0;36mPipeline.transform\u001b[1;34m(self, X, **params)\u001b[0m\n\u001b[0;32m    903\u001b[0m Xt \u001b[38;5;241m=\u001b[39m X\n\u001b[0;32m    904\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, name, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter():\n\u001b[1;32m--> 905\u001b[0m     Xt \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    906\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Xt\n",
      "File \u001b[1;32mc:\\project\\myenv\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:273\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 273\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    274\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    275\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    276\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    277\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    278\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    279\u001b[0m         )\n",
      "Cell \u001b[1;32mIn[137], line 6\u001b[0m, in \u001b[0;36mPrivatePoolTransformer.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: pd\u001b[38;5;241m.\u001b[39mDataFrame):\n\u001b[1;32m----> 6\u001b[0m     X[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrivatePool\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprivate pool\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mcombine_first(X[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrivatePool\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      7\u001b[0m     X\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprivate pool\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      8\u001b[0m     X[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrivatePool\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m X[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrivatePool\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmap({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myes\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYes\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m})\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mbool\u001b[39m)\n",
      "File \u001b[1;32mc:\\project\\myenv\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\project\\myenv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'private pool'"
     ]
    }
   ],
   "source": [
    "data_pipeline = Pipeline([\n",
    "    ('private_pool', PrivatePoolTransformer()), #корректно\n",
    "    ('fireplace_transformer', FireplaceTransformer()), #корректно \n",
    "    ('status_transformer', StatusToNumberTransformer()), #коректно \n",
    "    ('stories_transform', StoriesTransform()), #коректно \n",
    "    ('type_transform', PropertyTypeTransformer()), #коректно \n",
    "    ('home_features', HomeFeaturesExtractor()), #корректно\n",
    "    ('schools', SchoolFeaturesExtractor()),\n",
    "    ('fillna_sqft', fill_sqft(['baths', 'beds'])),\n",
    "    ('numbers', NumericExtractor(['baths','sqft', 'beds', 'target', 'lotsize','Year built','Remodeled year'])),\n",
    "    ('parking_sqft', ParkingPriceTransformer()),\n",
    "    ('stories', CustomImputerOutlierRemover()),\n",
    "    ('cooling_cat', CoolingTransformer()),\n",
    "    ('heating_cat', HeatingFeaturesTransformer()),\n",
    "    ('other_cat',  MinHashFeaturesTransformer(columns=['city', 'street', 'state'], n_components=2)),\n",
    "    ('year_features', YearFeaturesTransformer()), #d\n",
    "    ('outlier_remover', OutlierRemover()),\n",
    "    ('inplace_col_sqft', InplaceColTransformer(['baths', 'beds', 'PrivatePool', 'Average Rating'], 'sqft')),\n",
    "    ('round_baths', FunctionTransformer(lambda X: X.assign(baths=X['baths'].apply(round_to_nearest_half)), validate=False)),\n",
    "    ('inplace_col_baths', InplaceColTransformer(['sqft', 'beds', 'PrivatePool', 'Average Rating', 'property_age'], 'baths')),\n",
    "    ('round_beds', FunctionTransformer(lambda X: X.assign(beds=X['beds'].apply(round_to_nearest_half)), validate=False)),\n",
    "    ('inplace_col_beds', InplaceColTransformer(['sqft', 'baths', 'PrivatePool', 'Average Rating'], 'beds')),\n",
    "    ('inplace_col_price', InplaceColTransformer(['propertyType', 'baths', 'state_0', 'state_1', 'city_0', 'city_1', 'Average Rating','property_age'], 'Price/sqft')),\n",
    "    ('custom_features', CustomFeatureTransformer()),\n",
    "    ('other', Other()),\n",
    "\n",
    "])\n",
    "data = r.copy()\n",
    "data.drop_duplicates(inplace=True)\n",
    "data.dropna(subset=['target', 'street', 'city'], inplace=True)\n",
    "data.drop(['mls-id', 'MlsId'], axis=1, inplace=True)\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "data_pipeline.fit(data)\n",
    "pp = data_pipeline.transform(data.iloc[0:10])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
